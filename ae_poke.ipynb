{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d953a98a-e7b8-489b-b28c-d8416ef94474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import silhouette_score, rand_score, adjusted_rand_score, mean_squared_error\n",
    "from sklearn.mixture import BayesianGaussianMixture as BGM\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "\n",
    "from DataGenerator import DataGenerator\n",
    "import utils\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13be302e-26fb-4998-9619-2ac117e0d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPAE(nn.Module):\n",
    "  def __init__(self, in_components, out_components):\n",
    "    super(MLPAE, self).__init__()\n",
    "\n",
    "    self.in_features = in_components\n",
    "    self.out_features = out_components\n",
    "\n",
    "    self.Encoder = nn.Sequential(\n",
    "      nn.Linear(in_features=self.in_features, out_features=64),\n",
    "      nn.ReLU(inplace=False),\n",
    "      nn.Linear(in_features=64, out_features=self.out_features),\n",
    "      \n",
    "      # nn.Linear(in_features=self.in_features, out_features=256),\n",
    "      # nn.ReLU(inplace=False),\n",
    "      # nn.Linear(in_features=256, out_features=128),\n",
    "      # nn.ReLU(inplace=False),      \n",
    "      # nn.Linear(in_features=128, out_features=64),\n",
    "      # nn.ReLU(inplace=False),\n",
    "      # nn.Linear(in_features=64, out_features=32),\n",
    "      # nn.ReLU(inplace=False),  \n",
    "      # nn.Linear(in_features=32, out_features=self.out_features),\n",
    "      \n",
    "    )\n",
    "\n",
    "    self.Decoder = nn.Sequential(\n",
    "\n",
    "      nn.Linear(in_features=self.out_features, out_features=64),\n",
    "      # nn.Sigmoid()\n",
    "      nn.ReLU(inplace=False),      \n",
    "      nn.Linear(in_features=64, out_features=self.in_features),\n",
    "        \n",
    "      # nn.Linear(in_features=self.out_features, out_features=32),\n",
    "      # nn.ReLU(inplace=False),      \n",
    "      # nn.Linear(in_features=32, out_features=64),\n",
    "      # nn.ReLU(inplace=False),      \n",
    "      # nn.Linear(in_features=64, out_features=128),\n",
    "      # nn.ReLU(inplace=False),    \n",
    "      # nn.Linear(in_features=128, out_features=256),\n",
    "      # nn.ReLU(inplace=False),    \n",
    "      # nn.Linear(in_features=256, out_features=self.in_features),\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    encoder = self.Encoder(x)\n",
    "    decoder = self.Decoder(encoder)\n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcdc652f-69f2-4cfe-b26b-b813d0ec10ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, criterion, optimizer):\n",
    "  model.train()\n",
    "\n",
    "  train_loss = 0\n",
    "\n",
    "  for _, (data, _) in enumerate(train_loader):\n",
    "    \n",
    "    data = data.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    _, decoded_data = model(data)\n",
    "\n",
    "    loss = criterion(data, decoded_data)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    train_loss += loss.item()\n",
    "\n",
    "  avg_loss = train_loss / len(train_loader)\n",
    "  \n",
    "  return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0eaa52e9-fc65-47f9-b255-1cdfc8642753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(model, device, train_loader, test_loader, batch_size):\n",
    "  X_test = []\n",
    "  y_test = []\n",
    "  X_train = []\n",
    "  y_train = []\n",
    "    \n",
    "  decode_X_train = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for _, (data, labels) in enumerate(train_loader):\n",
    "      data = data.to(device)\n",
    "      labels = labels.to(device)\n",
    "\n",
    "      transformed_data, decoded_data = model(data)\n",
    "      transformed_data = np.asarray(transformed_data.detach().cpu().numpy())\n",
    "      decoded_data = np.asarray(decoded_data.detach().cpu().numpy())\n",
    "\n",
    "      X_train.append(transformed_data)\n",
    "      decode_X_train.append(decoded_data)\n",
    "\n",
    "    for _, (data, labels) in enumerate(test_loader):\n",
    "      data = data.to(device)\n",
    "      labels = labels.to(device)     \n",
    "\n",
    "      transformed_data, _ = model(data)\n",
    "      transformed_data = np.asarray(transformed_data.detach().cpu().numpy())\n",
    "\n",
    "      X_test.append(transformed_data)\n",
    "\n",
    "  X_train = np.reshape(np.asarray(X_train), (len(train_loader) * batch_size, 16))\n",
    "  X_test = np.reshape(np.asarray(X_test), (len(test_loader) * batch_size, 16))\n",
    "  decode_X_train = np.reshape(np.asarray(decode_X_train), (len(train_loader) * batch_size, IMAGE_DIM*IMAGE_DIM))\n",
    "\n",
    "  return X_train, X_test, decode_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "825c9420-ff7a-4249-a4b1-2ba2a6a04005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_K_means(X,n_clusters):\n",
    "  kmeans = KMeans(n_clusters=n_clusters).fit(X)\n",
    "  centers=kmeans.cluster_centers_\n",
    "  labels=kmeans.labels_\n",
    "  return centers, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec279641-f6d2-4ae3-9ce3-fbd511194f7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16000 15000  5000 10000 20000  5000  5000 12000  8000  4000]\n"
     ]
    }
   ],
   "source": [
    "#%% Try DNN on Image Dim\n",
    "TOTAL_POINTS = 100000\n",
    "IMAGE_DIM = 32\n",
    "OUTPUT_DIM = 16\n",
    "N_CLUSTERS = 10\n",
    "RATIOS = np.array([0.16,0.15,0.05,0.1,0.2,0.05,0.05,0.12,0.08,0.04]) # might need random assignments for ratio\n",
    "mode = 'clean' # 'clean' or 'noisy' for dae\n",
    "\n",
    "myGenerator = DataGenerator(samples=TOTAL_POINTS, n_features=IMAGE_DIM*IMAGE_DIM, n_clusters=N_CLUSTERS, spread=20, ratio_per_cluster=RATIOS, lower_bound=0, upper_bound=100)\n",
    "X, labels, centers = myGenerator.generate_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53a87136-6027-4f5f-a7e2-13436017cf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X = sc.transform(X)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0db471a4-cc37-4a36-94cc-6490032adc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5986891446746885\n",
      "-4.2678662381692005\n",
      "(100000, 1024)\n"
     ]
    }
   ],
   "source": [
    "### extra noise\n",
    "if mode == 'clean':\n",
    "  X_train_dnn = X_train\n",
    "elif mode == 'noisy':\n",
    "  noise_factor = 0.3\n",
    "  X_train_dnn = X_train + noise_factor * np.random.normal(size=X_train.shape) \n",
    "  # X_train_dnn = np.clip(X_train_dnn, 0.0, 1.0)\n",
    "else:\n",
    "  raise NotImplementedError(f\"Data noise mode \\\n",
    "    {mode} has to be either 'clean' or 'noisy'.\")\n",
    "    \n",
    "print(np.max(X_train_dnn))\n",
    "print(np.min(X_train_dnn))\n",
    "train_dataset = TensorDataset(torch.Tensor(X_train_dnn), torch.Tensor(y_train))\n",
    "test_dataset = TensorDataset(torch.Tensor(X_test), torch.Tensor(y_test))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbdc7ccf-e0da-46c4-ab3c-e2eec33d18c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:04<02:10,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for AE is: 0.11780418982729315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [00:08<01:54,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for AE is: 0.03244680617935956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [00:13<01:58,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for AE is: 0.03246400380507111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:16<01:46,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for AE is: 0.03235074270516634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [00:20<01:40,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for AE is: 0.03231270163320005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [00:25<01:42,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for AE is: 0.03236275712028146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [00:30<01:44,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for AE is: 0.03224179196171462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [00:34<01:36,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for AE is: 0.03219122551381588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [00:37<01:23,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for AE is: 0.03238511003553867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [00:41<01:20,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for AE is: 0.032109322333708404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [00:46<01:18,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for AE is: 0.03235670113004744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [00:49<01:09,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for AE is: 0.0320404402539134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [00:53<01:04,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for AE is: 0.03208434296771884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [00:57<01:03,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for AE is: 0.032004444105550645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [01:00<00:57,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for AE is: 0.03195901127532125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [01:04<00:54,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for AE is: 0.03203889303840697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [01:09<00:53,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for AE is: 0.031950424201786516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [01:13<00:50,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for AE is: 0.032013377957046035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [01:18<00:46,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for AE is: 0.03187935223802924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [01:21<00:39,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for AE is: 0.03182421729899943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [01:25<00:35,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for AE is: 0.03191923174075782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [01:29<00:31,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for AE is: 0.0318174885911867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [01:32<00:25,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for AE is: 0.03189264285378158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [01:36<00:22,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for AE is: 0.031707897344604136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [01:40<00:19,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for AE is: 0.03164501701015979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [01:44<00:15,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for AE is: 0.03200812905561179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [01:49<00:12,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for AE is: 0.03156158211175352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [01:52<00:07,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for AE is: 0.03144938453566283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [01:57<00:04,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for AE is: 0.03154616859741509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:01<00:00,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for AE is: 0.03143596573267132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 16)\n",
      "(80000, 16)\n",
      "(20000, 1024)\n"
     ]
    }
   ],
   "source": [
    "#%% DNN trial\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 50\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "train_losses = np.zeros(EPOCHS)\n",
    "model = MLPAE(in_components=IMAGE_DIM*IMAGE_DIM, out_components=OUTPUT_DIM).to(device)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "  train_loss = train(model, device, train_loader, criterion, optimizer)\n",
    "  # train_loss = CAE_train(model, device, train_loader, criterion, optimizer, lam=1e-4) # CAE\n",
    "\n",
    "  train_losses[epoch] = train_loss\n",
    "  print(f'Training loss for AE is: {train_loss}')\n",
    "\n",
    "X_train_dnn, X_test_dnn, decode_X_train_dnn = get_datasets(model, device, train_loader, test_loader, batch_size=BATCH_SIZE)\n",
    "print(X_train_dnn.shape)\n",
    "print(X_test_dnn.shape)\n",
    "print(decode_X_train_dnn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e9f0935-1777-4475-a295-a2465d8b47cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[ 4  7  9 10 14 28 38 43 44 45]\n"
     ]
    }
   ],
   "source": [
    "#fit dpgmm after pca\n",
    "clf_dp_dnn = BGM(n_components=50, weight_concentration_prior_type='dirichlet_process')\n",
    "clf_dp_dnn.fit(X_train_dnn)\n",
    "y_pred_dp_dnn = clf_dp_dnn.predict(X_train_dnn)\n",
    "\n",
    "a=np.unique(y_pred_dp_dnn)\n",
    "\n",
    "centers,res_k_means=fit_K_means(X_test,len(a))\n",
    "\n",
    "#scores\n",
    "dp_arscore_dnn = adjusted_rand_score(y_test, res_k_means)\n",
    "pred_clusters = set(res_k_means)\n",
    "\n",
    "print(dp_arscore_dnn)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9c23a55-a631-486f-a6e7-071de592f963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[ 0  3  8  9 11 14 16 21 22 28]\n"
     ]
    }
   ],
   "source": [
    "# pca\n",
    "pca = PCA(n_components=OUTPUT_DIM)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "#fit dpgmm after pca\n",
    "clf_dp_pca = BGM(n_components=50, weight_concentration_prior_type='dirichlet_process')\n",
    "clf_dp_pca.fit(X_train_pca)\n",
    "y_pred_dp_pca = clf_dp_pca.predict(X_train_pca)\n",
    "\n",
    "a=np.unique(y_pred_dp_pca)\n",
    "\n",
    "centers,res_k_means=fit_K_means(X_test,len(a))\n",
    "\n",
    "#scores\n",
    "dp_arscore_pca = adjusted_rand_score(y_test, res_k_means)\n",
    "pred_clusters = set(res_k_means)\n",
    "\n",
    "print(dp_arscore_pca)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaea859-530b-472f-ae38-ad65bda5f4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICA\n",
    "ica = FastICA(n_components=OUTPUT_DIM)\n",
    "X_train_ica = ica.fit_transform(X_train)\n",
    "X_test_ica = ica.transform(X_test)\n",
    "\n",
    "#fit dpgmm after pca\n",
    "clf_dp_ica = BGM(n_components=50, weight_concentration_prior_type='dirichlet_process')\n",
    "clf_dp_ica.fit(X_train_ica)\n",
    "y_pred_dp_ica = clf_dp_ica.predict(X_train_ica)\n",
    "\n",
    "a=np.unique(y_pred_dp_ica)\n",
    "\n",
    "centers,res_k_means=fit_K_means(X_test,len(a))\n",
    "\n",
    "#scores\n",
    "dp_arscore_ica = adjusted_rand_score(y_test, res_k_means)\n",
    "pred_clusters = set(res_k_means)\n",
    "\n",
    "print(dp_arscore_ica)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14f7be3-e96e-4da5-9d82-ecd67e83a3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE\n",
    "decode_X_train_pca = pca.inverse_transform(X_train_pca)\n",
    "decode_X_train_ica = ica.inverse_transform(X_train_ica)\n",
    "\n",
    "MSE_pca = mean_squared_error(decode_X_train_pca, X_train)\n",
    "MSE_ica = mean_squared_error(decode_X_train_ica, X_train)\n",
    "MSE_dnn = mean_squared_error(decode_X_train_dnn, X_train)\n",
    "print(MSE_pca)\n",
    "print(MSE_ica)\n",
    "print(MSE_dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1869fe36-b7e1-4041-9a49-dfbb80eebe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "df_pca = pd.DataFrame(data=X_train_pca, columns=(np.arange(X_train_pca.shape[1])))\n",
    "figure = plt.figure(1, figsize=(10,8))\n",
    "corr_mat_pca = df_pca.corr()\n",
    "sn.heatmap(corr_mat_pca, annot=False)\n",
    "plt.show()\n",
    "\n",
    "df_dnn = pd.DataFrame(data=X_train_dnn, columns=(np.arange(X_train_dnn.shape[1])))\n",
    "figure = plt.figure(2, figsize=(10,8))\n",
    "corr_mat_dnn = df_dnn.corr()\n",
    "sn.heatmap(corr_mat_dnn, annot=False)\n",
    "plt.show()\n",
    "\n",
    "df_ica = pd.DataFrame(data=X_train_ica, columns=(np.arange(X_train_ica.shape[1])))\n",
    "figure = plt.figure(3, figsize=(10,8))\n",
    "corr_mat_ica = df_ica.corr()\n",
    "sn.heatmap(corr_mat_ica, annot=False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
